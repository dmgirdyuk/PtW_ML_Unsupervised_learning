{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практика по кластеризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join('..', '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from abc import ABCMeta\n",
    "from collections import Counter\n",
    "from IPython.display import display\n",
    "from functools import lru_cache\n",
    "from ipywidgets import interact, fixed, IntSlider, FloatSlider\n",
    "from matplotlib import rcParams\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.cluster import (MeanShift, AgglomerativeClustering, DBSCAN,\n",
    "                             MiniBatchKMeans, KMeans, \n",
    "                             SpectralClustering)\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from typing import List\n",
    "\n",
    "from src.utils.common import get_data_folder, timeit\n",
    "from src.utils.plots import plot_dendrogram, plot_sorted_nn_dists\n",
    "\n",
    "%matplotlib inline\n",
    "rcParams['font.size'] = 14\n",
    "rcParams['figure.figsize'] = 9, 8\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 5\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Используемые данные.\n",
    "Проточная цитометрия — метод исследования дисперсных сред в режиме поштучного анализа элементов дисперсной фазы по сигналам светорассеяния и флуоресценции. Название метода связано с основным приложением, а именно, с исследованием одиночных биологических клеток в потоке.\n",
    "<img src=\"../../misc/cytometry.png\" width=\"680\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = get_data_folder()\n",
    "dfs = [pd.read_csv(os.path.join(data_folder, 'flowcytometry', file_name)) \n",
    "       for file_name in os.listdir(os.path.join(data_folder, 'flowcytometry'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, df in enumerate(dfs):\n",
    "    print(f'Patient {ind + 1}:', df.isnull().any().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = dfs[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterplot2d(df, col1='FSC-A-', col2='SSC-A-', \n",
    "                  labels=None, \n",
    "                  dots_size=6, palette='coolwarm'):\n",
    "    fig, _ = plt.subplots()\n",
    "    sns.scatterplot(df[col1], df[col2], hue=labels, s=dots_size, palette=palette)\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot2d(dfs[0], cols[1], cols[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# избавимся от части выбросов\n",
    "for i, df in enumerate(dfs):\n",
    "    mask = (df['FSC-A-'] > 200000) | (df['SSC-A-'] > 240000)\n",
    "    dfs[i] = df.drop(df[mask].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot2d(dfs[0], cols[1], cols[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основные алгоритмы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeit\n",
    "def clust_and_viz(df, clust_cols, clusterer, dots_size=5):\n",
    "    clusterer.fit(df[clust_cols])\n",
    "    labels = clusterer.labels_ if hasattr(clusterer, 'labels_') else clusterer.predict(df[clust_cols])\n",
    "    print(f'Число кластеров: {len(set(labels))}') \n",
    "    scatterplot2d(df, \n",
    "                  col1=clust_cols[0], \n",
    "                  col2=clust_cols[1], \n",
    "                  labels=labels, \n",
    "                  dots_size=dots_size)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs[0].copy()\n",
    "df_scaled = df.copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled[df_scaled.columns[1:]] = scaler.fit_transform(df_scaled[df_scaled.columns[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_cols = ['FSC-A-', 'SSC-A-']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meanshift\n",
    "\n",
    "docs: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MeanShift.html\n",
    "\n",
    "code: https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/cluster/_mean_shift.py#L243\n",
    "\n",
    "* Основной цикл со сдвигом сидов\\кернелов\\опорных точек (400 строчка): https://github.com/scikit-learn/scikit-learn/blob/95119c13af77c76e150b753485c662b7c52a41a2/sklearn/cluster/_mean_shift.py#L90\n",
    "* Строчки 422-435 -- Выбираем центры кластеров\n",
    "* Строчки 438-447 -- Расставляем метки кластеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_meanshift = MeanShift(bandwidth=None, \n",
    "                           min_bin_freq=1, \n",
    "                           cluster_all=True, \n",
    "                           bin_seeding=True, \n",
    "                           n_jobs=4)\n",
    "\n",
    "base_meanshift_labels = clust_and_viz(df_scaled, clust_cols, base_meanshift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_meanshift = MeanShift(bandwidth=0.7, \n",
    "                          min_bin_freq=3,  \n",
    "                          cluster_all=False, \n",
    "                          bin_seeding=True, \n",
    "                          n_jobs=4)\n",
    "\n",
    "opt_meanshift_labels = clust_and_viz(df_scaled, clust_cols, opt_meanshift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aglomerative clustering\n",
    "\n",
    "docs: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html\n",
    "\n",
    "code: https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/cluster/_agglomerative.py#L681\n",
    "\n",
    "* При ближайшем рассмотрении выясняется, что сам по себе алгоритм подтягивается из scipy.cluster.hierarchy:\n",
    "\n",
    "    ** ward_tree: https://github.com/scikit-learn/scikit-learn/blob/95119c13af77c76e150b753485c662b7c52a41a2/sklearn/cluster/_agglomerative.py#L138  (строка 236)\n",
    "    \n",
    "    ** https://github.com/scipy/scipy/blob/5ab7426247900db9de856e790b8bea1bd71aec49/scipy/cluster/hierarchy.py#L738\n",
    "    \n",
    "    ** https://github.com/scipy/scipy/blob/5ab7426247900db9de856e790b8bea1bd71aec49/scipy/cluster/hierarchy.py#L837\n",
    "    \n",
    "    ** https://github.com/scipy/scipy/blob/5ab7426247900db9de856e790b8bea1bd71aec49/scipy/cluster/_hierarchy.pyx#L908\n",
    "    \n",
    "    ** вычисление метрик связи: https://github.com/scipy/scipy/blob/5ab7426247900db9de856e790b8bea1bd71aec49/scipy/cluster/_hierarchy_distance_update.pxi\n",
    "\n",
    "* Своя версия есть только в контексте работы с матрицей связи (connectivity matrix) -- это про накидывание локальной структуры связи между данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_agglomerative = AgglomerativeClustering(n_clusters=2,  # может быть None\n",
    "                                             affinity='euclidean', \n",
    "                                             linkage='ward')\n",
    "\n",
    "base_agglomerative_labels = clust_and_viz(df_scaled, clust_cols, base_agglomerative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_agglomerative = AgglomerativeClustering(n_clusters=None,\n",
    "                                             distance_threshold=0, \n",
    "                                             affinity='euclidean', \n",
    "                                             linkage='average')\n",
    "full_agglomerative.fit(df_scaled[clust_cols])\n",
    "\n",
    "plot_dendrogram(full_agglomerative, truncate_mode='level', p=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_agglomerative = AgglomerativeClustering(n_clusters=15,\n",
    "                                            affinity='euclidean', \n",
    "                                            linkage='average')\n",
    "\n",
    "opt_agglomerative_labels = clust_and_viz(df_scaled, clust_cols, opt_agglomerative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBSCAN\n",
    "\n",
    "docs: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html\n",
    "\n",
    "code: https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/cluster/_dbscan.py#L148\n",
    "\n",
    "code (cython part): https://github.com/scikit-learn/scikit-learn/blob/95119c13af77c76e150b753485c662b7c52a41a2/sklearn/cluster/_dbscan_inner.pyx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sorted_nn_dists(df_scaled[clust_cols], min_pts=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dbscan = DBSCAN(eps=0.5, \n",
    "                     min_samples=4, \n",
    "                     metric='euclidean', \n",
    "                     n_jobs=4)\n",
    "\n",
    "base_dbscan_labels = clust_and_viz(df_scaled, clust_cols, base_dbscan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_dbscan = DBSCAN(eps=0.04, \n",
    "                    min_samples=4, \n",
    "                    metric='euclidean', \n",
    "                    n_jobs=4)\n",
    "\n",
    "opt_dbscan_labels = clust_and_viz(df_scaled, clust_cols, opt_dbscan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter(opt_dbscan_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot2d(df_scaled, clust_cols[0], clust_cols[1], labels=opt_dbscan_labels==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Mixture Model (Expectation Maximization)\n",
    "\n",
    "docs: https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html\n",
    "\n",
    "code: https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/mixture/_gaussian_mixture.py#L434\n",
    "\n",
    "code (BaseMixture class): https://github.com/scikit-learn/scikit-learn/blob/95119c13af77c76e150b753485c662b7c52a41a2/sklearn/mixture/_base.py#L484\n",
    "\n",
    "fit-метод вызывается из BaseMixture. В GMM лишь определяется m-шаг, выполняющий пересчет параметров распределения (нормального, в данном случае)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_gmm = GaussianMixture(n_components=1, \n",
    "                           covariance_type='full',\n",
    "                           n_init=1, \n",
    "                           init_params='kmeans', \n",
    "                           random_state=SEED)\n",
    "\n",
    "base_gmm_labels = clust_and_viz(df_scaled, clust_cols, base_gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_gmm = GaussianMixture(n_components=4, \n",
    "                          covariance_type='full',\n",
    "                          n_init=5, \n",
    "                          init_params='kmeans', \n",
    "                          random_state=SEED)\n",
    "\n",
    "opt_gmm_labels = clust_and_viz(df_scaled, clust_cols, opt_gmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectral clustering\n",
    "\n",
    "docs: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html\n",
    "\n",
    "code: https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/cluster/_spectral.py#L287\n",
    "* Вычисляем матрицу связи и вызываем метод spectral_clustering: https://github.com/scikit-learn/scikit-learn/blob/95119c13af77c76e150b753485c662b7c52a41a2/sklearn/cluster/_spectral.py#L162\n",
    "\n",
    "* Внутри которого строится спектральный эмбеддинг (https://github.com/scikit-learn/scikit-learn/blob/95119c13af77c76e150b753485c662b7c52a41a2/sklearn/manifold/_spectral_embedding.py#L145) \n",
    "\n",
    "    ** Лапласиан строится функцией laplacian из scipy.sparse.csgraph: https://github.com/scipy/scipy/blob/v1.6.1/scipy/sparse/csgraph/_laplacian.py#L16-L79\n",
    "\n",
    "* и запускается метод кластеризации (kmeans по дефолту)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_spectral = SpectralClustering(n_clusters=8, \n",
    "                                   # n_components=8, \n",
    "                                   random_state=SEED, \n",
    "                                   n_init=10, \n",
    "                                   affinity='nearest_neighbors', \n",
    "                                   n_neighbors=10, \n",
    "                                   assign_labels='kmeans', \n",
    "                                   n_jobs=4)\n",
    "\n",
    "base_spectral_labels = clust_and_viz(df_scaled, clust_cols, base_spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_spectral = SpectralClustering(n_clusters=5, \n",
    "                                  n_components=2, \n",
    "                                  random_state=SEED, \n",
    "                                  n_init=5, \n",
    "                                  affinity='nearest_neighbors', \n",
    "                                  n_neighbors=25, \n",
    "                                  assign_labels='kmeans', \n",
    "                                  n_jobs=4)\n",
    "\n",
    "opt_spectral_labels = clust_and_viz(df_scaled, clust_cols, opt_spectral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бонусная секция\n",
    "\n",
    "Создадим словарик с рассмотренными методами (и k-means'ом, куда ж без него)\n",
    "и ограничениями на их основные параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = {\n",
    "    'meanshift': {'method': MeanShift, \n",
    "                  'params_range': {'bandwidth': [1] + list(np.arange(0.3, 1.5, 0.05)) + [None], \n",
    "                                   'bin_seeding': [True, False], \n",
    "                                   'n_jobs': [*range(1, 5), -1]}\n",
    "                 }, \n",
    "    'agglomerative': {'method': AgglomerativeClustering, \n",
    "                      'params_range': {'n_clusters': [*range(2, 50)], \n",
    "                                       'affinity': ['euclidean', 'manhattan'], \n",
    "                                       'linkage': ['ward', 'complete', 'average', 'single']}}, \n",
    "    'dbscan': {'method': DBSCAN, \n",
    "               'params_range': {'eps': [*np.arange(0.01, 0.2, 0.01)], \n",
    "                                'min_samples': [*range(1, 26)], \n",
    "                                'metric': ['euclidean', 'manhattan'],\n",
    "                                'n_jobs': [*range(1, 5), -1]}},\n",
    "    'em': {'method': GaussianMixture, \n",
    "           'params_range': {'n_components': [*range(2, 50)], \n",
    "                            'covariance_type': ['full', 'tied', 'diag', 'spherical'],\n",
    "                            'n_init': [*range(1, 6)],\n",
    "                            'init_params': ['kmeans', 'random'],\n",
    "                            'random_state': fixed(SEED)}}, \n",
    "    'kmeans': {'method': KMeans, \n",
    "               'params_range': {'n_clusters': [*range(2, 50)],\n",
    "                                'n_init': [*range(5, 25)],\n",
    "                                'random_state': fixed(SEED), \n",
    "                                'n_jobs': [*range(1, 5), -1]}},\n",
    "    'mbkmeans': {'method': MiniBatchKMeans, \n",
    "                 'params_range': {'n_clusters': [*range(2, 50)], \n",
    "                                  'batch_size': [*range(100, 1001, 100)],\n",
    "                                  'n_init': [*range(3, 8)],\n",
    "                                  'random_state': fixed(SEED)}},\n",
    "    'spectral': {'method': SpectralClustering, \n",
    "                 'params_range': {'n_clusters': [*range(2, 50)], \n",
    "                                  'n_components': [*range(2, 50)],\n",
    "                                  'affinity': ['nearest_neighbors'], \n",
    "                                  'gamma': [*np.arange(0.5, 2, 0.1)],\n",
    "                                  'n_neighbors': [*range(2, 25)],                         \n",
    "                                  'assign_labels': ['kmeans', 'discretize'], \n",
    "                                  'n_init': [*range(10, 25)],\n",
    "                                  'random_state': fixed(SEED), \n",
    "                                  'n_jobs': [*range(1, 5), -1]}}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запилим класс, который будет кластеризовать данные и отрисовывать результаты в зависимости от поданных в его метод analysis2d параметров.\n",
    "\n",
    "Кэшируем результаты фит-предикта, чтобы не пересчитывать все заново, если изменим размер точек на графике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractiveClusterer:\n",
    "    def __init__(self, \n",
    "                 method: str, \n",
    "                 params_range: dict, \n",
    "                 dfs: List[pd.DataFrame], \n",
    "                 scaler: TransformerMixin = MinMaxScaler()):\n",
    "        self.method = method\n",
    "        self.clusterer = None\n",
    "        self.params_range = params_range\n",
    "        self.dfs = dfs\n",
    "        self.curr_df = None\n",
    "        \n",
    "    @lru_cache(maxsize=None)\n",
    "    def fit_predict(self, \n",
    "                    patient=0, \n",
    "                    col1='FSC-A-', \n",
    "                    col2='SSC-A-', \n",
    "                    do_scaling=False, \n",
    "                    **kwargs): \n",
    "        # параметры вне kwargs нужны для кэширования результатов\n",
    "        self.clusterer = self.method(**kwargs)\n",
    "        self.clusterer.fit(self.curr_df)\n",
    "        \n",
    "        if not isinstance(self.method, ABCMeta):\n",
    "            return self.clusterer.labels_  \n",
    "        else:\n",
    "            # для случая GMM\n",
    "            return self.clusterer.predict(self.curr_df)\n",
    "    \n",
    "    def analysis2d(self, \n",
    "                   print_clust_num=False, \n",
    "                   dots_size=5, \n",
    "                   palette='coolwarm', \n",
    "                   patient=0, \n",
    "                   col1='FSC-A-', \n",
    "                   col2='SSC-A-', \n",
    "                   do_scaling=True, \n",
    "                   plot_scaled=True, \n",
    "                   **kwargs):\n",
    "        self.curr_df = self.dfs[patient][[col1, col2]].copy()\n",
    "        \n",
    "        if do_scaling:\n",
    "            self.curr_df[self.curr_df.columns] = scaler.fit_transform(self.curr_df)\n",
    "        \n",
    "        labels = self.fit_predict(patient=patient, col1=col1, col2=col2, do_scaling=do_scaling, **kwargs)\n",
    "\n",
    "        if print_clust_num:\n",
    "            print('Число кластеров:', len(set(labels)))\n",
    "        \n",
    "        scatterplot2d(self.curr_df if plot_scaled else self.dfs[patient], \n",
    "                      col1=col1, col2=col2, labels=labels, dots_size=dots_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбираем метод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_name = 'dbscan'\n",
    "params_range = clustering[method_name]['params_range']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем инстанс класса и прокидываем в него метод, границы на его параметры, данные и нормализатор (ощутил всю боль переводчиков)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()  #MinMaxScaler()\n",
    "clusterer = InteractiveClusterer(**clustering[method_name], \n",
    "                                 dfs=dfs, \n",
    "                                 scaler=scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И, магия. Юпитеровский виждет: https://ipywidgets.readthedocs.io/en/latest/examples/Using%20Interact.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interact(clusterer.analysis2d, \n",
    "         print_clust_num=True, \n",
    "         dots_size=[*range(1, 15)], \n",
    "         palette='coolwarm', \n",
    "         patient=[*range(0, 5)], \n",
    "         col1=cols, \n",
    "         col2=cols,\n",
    "         do_scaling=[False, True], \n",
    "         plot_scaled=[False, True],\n",
    "         **params_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
